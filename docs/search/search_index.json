{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Home FalconCV is an open-source Python library that offers developers an interface to interact with some of the most popular computer vision frameworks, such as TensorFlow Object detection API and Detectron. The main objective behind it is to unify the set of tools available and simplify the use of them. This library is focused mainly on Computer Vision practitioners but also is flexible enough to allow researchers to configure the models at a low-level. Additionally, taking advantage of the fantastic features that OpenVINO offers, a custom model can be trained and optimized to run efficiently in the target hardware with just a few lines of code. It is important to say that FalconCV does not attempt to replace any of the tools mentioned previously; instead, it takes the best of them and offers a solution to improve accessibility to new users. Warning This is a pre-release version of the FalconCV, which is still undergoing final testing before its official release. The website, its software and all content found on it are provided on an \"as is\" and \"as available\" basis. We hope to release an stable version soon. Another consideration is that FalconCV is compatible only with TensorFlow 1.x for now. Install FalconCV from GitHub source Create environment Download and install Anaconda (Python 3+). Open the anaconda terminal and execute: 1 conda create --name falconcv python=3.6 Install dependencies 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 pip install matplotlib pip install numpy==1.17 pip install opencv-contrib-python pip install pillow pip install cython pip install tqdm pip install scipy pip install requests pip install clint pip install validators pip install more-itertools pip install pandas pip install imutils pip install boto3 pip install \"dask[complete]\" pip install lxml pip install Mako pip install colorlog pip install colorama pip install bs4 pip install pick pip install -U scikit-learn pip install gitpython Linux 1 2 3 conda install -c anaconda wxpython sudo apt install protobuf-compiler pip install pycocotools Windows 1 2 3 pip install wmi pip install windows-curses pip install pycocotools-win Install backends TensorFlow: 1 conda install tensorflow-gpu==1.15.0 Install FalconCV from Github 1 pip uninstall falconcv -y && pip install git+https://github.com/haruiz/FalconCV.git","title":"Home"},{"location":"#home","text":"FalconCV is an open-source Python library that offers developers an interface to interact with some of the most popular computer vision frameworks, such as TensorFlow Object detection API and Detectron. The main objective behind it is to unify the set of tools available and simplify the use of them. This library is focused mainly on Computer Vision practitioners but also is flexible enough to allow researchers to configure the models at a low-level. Additionally, taking advantage of the fantastic features that OpenVINO offers, a custom model can be trained and optimized to run efficiently in the target hardware with just a few lines of code. It is important to say that FalconCV does not attempt to replace any of the tools mentioned previously; instead, it takes the best of them and offers a solution to improve accessibility to new users. Warning This is a pre-release version of the FalconCV, which is still undergoing final testing before its official release. The website, its software and all content found on it are provided on an \"as is\" and \"as available\" basis. We hope to release an stable version soon. Another consideration is that FalconCV is compatible only with TensorFlow 1.x for now.","title":"Home"},{"location":"#install-falconcv-from-github-source","text":"","title":"Install FalconCV from GitHub source"},{"location":"#create-environment","text":"Download and install Anaconda (Python 3+). Open the anaconda terminal and execute: 1 conda create --name falconcv python=3.6","title":"Create environment"},{"location":"#install-dependencies","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 pip install matplotlib pip install numpy==1.17 pip install opencv-contrib-python pip install pillow pip install cython pip install tqdm pip install scipy pip install requests pip install clint pip install validators pip install more-itertools pip install pandas pip install imutils pip install boto3 pip install \"dask[complete]\" pip install lxml pip install Mako pip install colorlog pip install colorama pip install bs4 pip install pick pip install -U scikit-learn pip install gitpython Linux 1 2 3 conda install -c anaconda wxpython sudo apt install protobuf-compiler pip install pycocotools Windows 1 2 3 pip install wmi pip install windows-curses pip install pycocotools-win","title":"Install dependencies"},{"location":"#install-backends","text":"TensorFlow: 1 conda install tensorflow-gpu==1.15.0","title":"Install backends"},{"location":"#install-falconcv-from-github","text":"1 pip uninstall falconcv -y && pip install git+https://github.com/haruiz/FalconCV.git","title":"Install FalconCV from Github"},{"location":"about/","text":"About","title":"About"},{"location":"about/#about","text":"","title":"About"},{"location":"datasets/","text":"Datasets Open Images Dataset Open Images is a dataset of ~9M images annotated with image-level labels, object bounding boxes, object segmentation masks, visual relationships, and localized narratives. It contains a total of 16M bounding boxes for 600 object classes on 1.9M images, making it the largest existing dataset with object location annotations. The boxes have been largely manually drawn by professional annotators to ensure accuracy and consistency. FalconCV only supports versions 5 and 6 of Open Images Dataset 1 Setup Method: parameter description values example split split for dataset train, test, validation split=\"train\" (default: train) task computer vision task detection task=\"detection\" (default: detection) Fetch Method: parameter description values example n number of images by class int n=100 labels target labels int labels=[\"Bear\", \"Elephant\"] batch_size images to load in memory int batch_size=100 (default: 200) Open Images Dataset 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 import os from falconcv.ds import * from falconcv.util import FileUtil , ImageUtil if __name__ == '__main__' : # create dataset dataset = OpenImages ( v = 6 ) # versions 5 and 6 supported dataset . setup ( split = \"train\" , task = \"detection\" ) # create ouput folder out_folder = \"<output folder>\" os . makedirs ( out_folder , exist_ok = True ) # optional: clear folder if already exists FileUtil . clear_folder ( out_folder ) for batch_images in dataset . fetch ( n = 100 , # number of images by class labels = [ \"Bear\" , \"Elephant\" ], # target labels batch_size = 100 # n images to load in memory ): # access to batch images for img in batch_images : # export images to disk img . export ( images_folder ) for region in img . regions : print ( region . shape_attributes [ \"x\" ], region . shape_attributes [ \"y\" ]) COCO Dataset COCO is a large-scale object detection, segmentation, and captioning dataset. COCO has several features: Object segmentation, Recognition in context, Superpixel stuff segmentation, 330K images (>200K labeled). FalconCV only supports version 2017 of COCO Dataset. 2 Setup Method: parameter description values example split split for dataset train, validation split=\"train\" (default: train) task computer vision task detection, segmentation task=\"detection\" (default: detection) Fetch Method: parameter description values example n number of images by class integer n=100 labels target labels integer labels=[\"Bear\", \"Elephant\"] batch_size images to load in memory integer batch_size=100 (default: 200) COCO (Common Objects in Context) 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 import os from falconcv.ds import * from falconcv.util import FileUtil , ImageUtil if __name__ == '__main__' : # create dataset dataset = Coco ( v = 2017 ) # only 2017 version is supported dataset . setup ( split = \"train\" , task = \"detection\" ) # create ouput folder out_folder = \"<output folder>\" os . makedirs ( out_folder , exist_ok = True ) # optional: clear folder if already exists FileUtil . clear_folder ( out_folder ) for batch_images in dataset . fetch ( n = 100 , # number of images by class labels = [ \"Mouse\" ], # target labels batch_size = 100 # n images to load in memory ): # Do something cool with the images for img in batch_images : # export images to disk img . export ( images_folder ) for region in img . regions : print ( region . shape_attributes [ \"x\" ], region . shape_attributes [ \"y\" ]) Scrappers Use FalconCV's scrappers to download images from Bing and Flicker. Bing Images Scrapper Fetch Method: parameter description values example q images to search string q=\"bear\" count number of images integer count=150 (default: 100) batch_size images to load in memory integer batch_size=100 (default: 200) timestamp time to wait between requests integer timestamp=5 (default: 1) Info How to generate the subscription key? https://azure.microsoft.com/en-us/try/cognitive-services/my-apis/?api=search-api-v7 Download images from bing 1 2 3 4 5 6 7 8 9 10 11 import uuid , os import cv2 from falconcv.ds import * if __name__ == '__main__' : out_folder = \"<out folder>\" scrapper = BingScrapper ( \"<Subscription Key>\" ) for images_batch in scrapper . fetch ( q = \"cockroach\" , batch_size = 80 ): for img in images_batch : # copy the images to the disk or do whatever you want cv2 . imwrite ( os . path . join ( out_folder , \" {} .jpg\" . format ( str ( uuid . uuid4 ()))), img ) Flickr Images Scrapper Fetch Method: parameter description values example q images to search string q=[\"cockroach\"] batch_size images to load in memory integer batch_size=100 (default: 100) timestamp time to wait between requests integer timestamp=5 (default: 1) sz images sizes (check list below) string sz=\"url_o\" (default: url_m) List of sizes: url_o: Original (4520 \u00d7 3229) url_k: Large 2048 (2048 \u00d7 1463) url_h: Large 1600 (1600 \u00d7 1143) url_l: Large 1024 (1024 \u00d7 732) url_c: Medium 800 (800 \u00d7 572) url_z: Medium 640 (640 \u00d7 457) url_m: Medium 500 (500 \u00d7 357) url_n: Small 320 (320 \u00d7 229) url_s: Small 240 (240 \u00d7 171) url_t: Thumbnail (100 \u00d7 71) url_q: Square 150 (150 \u00d7 150) url_sq: Square 75 (75 \u00d7 75) Info How to generate the API key?? https://www.flickr.com/services/api/misc.api_keys.html Download images from Flickr 1 2 3 4 5 6 7 8 9 10 11 import uuid , os import cv2 from falconcv.ds import * if __name__ == '__main__' : out_folder = r \"<out folder>\" scrapper = FlickrScrapper ( api_key = \"<Api Key>\" ) for batch in scrapper . fetch ( q = [ \"cockroach\" ], batch_size = 80 ): for img in batch : # copy the images to the disk or do whatever you want cv2 . imwrite ( os . path . join ( out_folder , \" {} .jpg\" . format ( str ( uuid . uuid4 ()))), img ) https://storage.googleapis.com/openimages/web/index.html \u21a9 http://cocodataset.org/ \u21a9","title":"Datasets"},{"location":"datasets/#datasets","text":"","title":"Datasets"},{"location":"datasets/#open-images-dataset","text":"Open Images is a dataset of ~9M images annotated with image-level labels, object bounding boxes, object segmentation masks, visual relationships, and localized narratives. It contains a total of 16M bounding boxes for 600 object classes on 1.9M images, making it the largest existing dataset with object location annotations. The boxes have been largely manually drawn by professional annotators to ensure accuracy and consistency. FalconCV only supports versions 5 and 6 of Open Images Dataset 1 Setup Method: parameter description values example split split for dataset train, test, validation split=\"train\" (default: train) task computer vision task detection task=\"detection\" (default: detection) Fetch Method: parameter description values example n number of images by class int n=100 labels target labels int labels=[\"Bear\", \"Elephant\"] batch_size images to load in memory int batch_size=100 (default: 200) Open Images Dataset 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 import os from falconcv.ds import * from falconcv.util import FileUtil , ImageUtil if __name__ == '__main__' : # create dataset dataset = OpenImages ( v = 6 ) # versions 5 and 6 supported dataset . setup ( split = \"train\" , task = \"detection\" ) # create ouput folder out_folder = \"<output folder>\" os . makedirs ( out_folder , exist_ok = True ) # optional: clear folder if already exists FileUtil . clear_folder ( out_folder ) for batch_images in dataset . fetch ( n = 100 , # number of images by class labels = [ \"Bear\" , \"Elephant\" ], # target labels batch_size = 100 # n images to load in memory ): # access to batch images for img in batch_images : # export images to disk img . export ( images_folder ) for region in img . regions : print ( region . shape_attributes [ \"x\" ], region . shape_attributes [ \"y\" ])","title":"Open Images Dataset"},{"location":"datasets/#coco-dataset","text":"COCO is a large-scale object detection, segmentation, and captioning dataset. COCO has several features: Object segmentation, Recognition in context, Superpixel stuff segmentation, 330K images (>200K labeled). FalconCV only supports version 2017 of COCO Dataset. 2 Setup Method: parameter description values example split split for dataset train, validation split=\"train\" (default: train) task computer vision task detection, segmentation task=\"detection\" (default: detection) Fetch Method: parameter description values example n number of images by class integer n=100 labels target labels integer labels=[\"Bear\", \"Elephant\"] batch_size images to load in memory integer batch_size=100 (default: 200) COCO (Common Objects in Context) 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 import os from falconcv.ds import * from falconcv.util import FileUtil , ImageUtil if __name__ == '__main__' : # create dataset dataset = Coco ( v = 2017 ) # only 2017 version is supported dataset . setup ( split = \"train\" , task = \"detection\" ) # create ouput folder out_folder = \"<output folder>\" os . makedirs ( out_folder , exist_ok = True ) # optional: clear folder if already exists FileUtil . clear_folder ( out_folder ) for batch_images in dataset . fetch ( n = 100 , # number of images by class labels = [ \"Mouse\" ], # target labels batch_size = 100 # n images to load in memory ): # Do something cool with the images for img in batch_images : # export images to disk img . export ( images_folder ) for region in img . regions : print ( region . shape_attributes [ \"x\" ], region . shape_attributes [ \"y\" ])","title":"COCO Dataset"},{"location":"datasets/#scrappers","text":"Use FalconCV's scrappers to download images from Bing and Flicker.","title":"Scrappers"},{"location":"datasets/#bing-images-scrapper","text":"Fetch Method: parameter description values example q images to search string q=\"bear\" count number of images integer count=150 (default: 100) batch_size images to load in memory integer batch_size=100 (default: 200) timestamp time to wait between requests integer timestamp=5 (default: 1) Info How to generate the subscription key? https://azure.microsoft.com/en-us/try/cognitive-services/my-apis/?api=search-api-v7 Download images from bing 1 2 3 4 5 6 7 8 9 10 11 import uuid , os import cv2 from falconcv.ds import * if __name__ == '__main__' : out_folder = \"<out folder>\" scrapper = BingScrapper ( \"<Subscription Key>\" ) for images_batch in scrapper . fetch ( q = \"cockroach\" , batch_size = 80 ): for img in images_batch : # copy the images to the disk or do whatever you want cv2 . imwrite ( os . path . join ( out_folder , \" {} .jpg\" . format ( str ( uuid . uuid4 ()))), img )","title":"Bing Images Scrapper"},{"location":"datasets/#flickr-images-scrapper","text":"Fetch Method: parameter description values example q images to search string q=[\"cockroach\"] batch_size images to load in memory integer batch_size=100 (default: 100) timestamp time to wait between requests integer timestamp=5 (default: 1) sz images sizes (check list below) string sz=\"url_o\" (default: url_m) List of sizes: url_o: Original (4520 \u00d7 3229) url_k: Large 2048 (2048 \u00d7 1463) url_h: Large 1600 (1600 \u00d7 1143) url_l: Large 1024 (1024 \u00d7 732) url_c: Medium 800 (800 \u00d7 572) url_z: Medium 640 (640 \u00d7 457) url_m: Medium 500 (500 \u00d7 357) url_n: Small 320 (320 \u00d7 229) url_s: Small 240 (240 \u00d7 171) url_t: Thumbnail (100 \u00d7 71) url_q: Square 150 (150 \u00d7 150) url_sq: Square 75 (75 \u00d7 75) Info How to generate the API key?? https://www.flickr.com/services/api/misc.api_keys.html Download images from Flickr 1 2 3 4 5 6 7 8 9 10 11 import uuid , os import cv2 from falconcv.ds import * if __name__ == '__main__' : out_folder = r \"<out folder>\" scrapper = FlickrScrapper ( api_key = \"<Api Key>\" ) for batch in scrapper . fetch ( q = [ \"cockroach\" ], batch_size = 80 ): for img in batch : # copy the images to the disk or do whatever you want cv2 . imwrite ( os . path . join ( out_folder , \" {} .jpg\" . format ( str ( uuid . uuid4 ()))), img ) https://storage.googleapis.com/openimages/web/index.html \u21a9 http://cocodataset.org/ \u21a9","title":"Flickr Images Scrapper"},{"location":"models/","text":"Models FalconCV offers a interface to work with the models from the Tensorflow Object Detection API 1 Load a pre-trained model parameter description model path to saved model labels_map path to the labels map (*.pbtxt) Load Saved model 1 2 3 4 5 6 7 8 9 from falconcv.models import ModelBuilder from falconcv.util import VIUtil import falconcv as fcv if __name__ == '__main__' : # load saved model with ModelBuilder . build ( \"<path to saved model>\" , \"<path to the labels map>\" ) as model : img , predictions = model . predict ( \"<image path | image uri >\" ) VIUtil . imshow ( img , predictions ) parameter description model path to the freeze model (*.pb) labels_map path to the labels map (*.pbtxt) Load Freeze model 1 2 3 4 5 6 7 8 9 from falconcv.models import ModelBuilder from falconcv.util import VIUtil import falconcv as fcv if __name__ == '__main__' : # load freeze model with ModelBuilder . build ( \"<path to the freeze model *.pb>\" , \"<path to the labels map>\" ) as model : img , predictions = model . predict ( \"< image path | image uri >\" ) VIUtil . imshow ( img , predictions ) Train Custom model Build: parameter description config dictionary with configuration for training Train: parameter description example epochs number of epochs epochs=200 (default: 100) val_split split percentage for val val_split=0.2 (default: 0.3) clear_folder clear folder clear_folder=False (default: False) override_pipeline override the pipeline file override_pipeline=False (default: False) eval indicates if make eval while training eval=True (default: False) Train Custom model 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 from falconcv.models import ModelBuilder from falconcv.util import VIUtil import falconcv as fcv if __name__ == '__main__' : config = { \"model\" : model_name , \"images_folder\" : images_folder , \"output_folder\" : out_folder , \"labels_map\" : labels_map , } with ModelBuilder . build ( config = config ) as model : model . train ( epochs = epochs , val_split = 0.3 , clear_folder = False ) # for freezing the model model . freeze ( chekpoint = epochs ) List TFODAPI models zoo 1 2 3 4 5 6 7 8 from falconcv.models.tf import ModelZoo if __name__ == '__main__' : # only faster_rcnn ModelZoo . print_available_models ( arch = \"faster\" ) # print all ModelZoo . print_available_models () https://github.com/tensorflow/models \u21a9","title":"Models"},{"location":"models/#models","text":"FalconCV offers a interface to work with the models from the Tensorflow Object Detection API 1","title":"Models"},{"location":"models/#load-a-pre-trained-model","text":"parameter description model path to saved model labels_map path to the labels map (*.pbtxt) Load Saved model 1 2 3 4 5 6 7 8 9 from falconcv.models import ModelBuilder from falconcv.util import VIUtil import falconcv as fcv if __name__ == '__main__' : # load saved model with ModelBuilder . build ( \"<path to saved model>\" , \"<path to the labels map>\" ) as model : img , predictions = model . predict ( \"<image path | image uri >\" ) VIUtil . imshow ( img , predictions ) parameter description model path to the freeze model (*.pb) labels_map path to the labels map (*.pbtxt) Load Freeze model 1 2 3 4 5 6 7 8 9 from falconcv.models import ModelBuilder from falconcv.util import VIUtil import falconcv as fcv if __name__ == '__main__' : # load freeze model with ModelBuilder . build ( \"<path to the freeze model *.pb>\" , \"<path to the labels map>\" ) as model : img , predictions = model . predict ( \"< image path | image uri >\" ) VIUtil . imshow ( img , predictions )","title":"Load a pre-trained model"},{"location":"models/#train-custom-model","text":"Build: parameter description config dictionary with configuration for training Train: parameter description example epochs number of epochs epochs=200 (default: 100) val_split split percentage for val val_split=0.2 (default: 0.3) clear_folder clear folder clear_folder=False (default: False) override_pipeline override the pipeline file override_pipeline=False (default: False) eval indicates if make eval while training eval=True (default: False) Train Custom model 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 from falconcv.models import ModelBuilder from falconcv.util import VIUtil import falconcv as fcv if __name__ == '__main__' : config = { \"model\" : model_name , \"images_folder\" : images_folder , \"output_folder\" : out_folder , \"labels_map\" : labels_map , } with ModelBuilder . build ( config = config ) as model : model . train ( epochs = epochs , val_split = 0.3 , clear_folder = False ) # for freezing the model model . freeze ( chekpoint = epochs ) List TFODAPI models zoo 1 2 3 4 5 6 7 8 from falconcv.models.tf import ModelZoo if __name__ == '__main__' : # only faster_rcnn ModelZoo . print_available_models ( arch = \"faster\" ) # print all ModelZoo . print_available_models () https://github.com/tensorflow/models \u21a9","title":"Train Custom model"}]}